{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # hides warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # hides deprecation warning\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning) # hides user warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv = \"br.csv\"\n",
    "data = pd.read_csv(csv, engine='python', error_bad_lines=False)\n",
    "# use python engine for more feature-complete\n",
    "# skips error bad line\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.filter(items=['reviewerName', 'title', 'reviewerRatings'])\n",
    "# filters the items that we need\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checks for missing value for each column (back slash for line break)\n",
    "for missing in\\\n",
    "(df['reviewerName'].isnull().value_counts(),\n",
    " df['title'].isnull().value_counts(),\n",
    " df['reviewerRatings'].isnull().value_counts()):\n",
    "    print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops missing values for all columns\n",
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checks for missing value again\n",
    "for missing in\\\n",
    "(df['reviewerName'].isnull().value_counts(),\n",
    " df['title'].isnull().value_counts(),\n",
    " df['reviewerRatings'].isnull().value_counts()):\n",
    "    print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove rows with non-ASCII characters in reviewerName and title column\n",
    "df = df[~df.reviewerName.str.contains(r'[^\\x00-\\x7F]')]\n",
    "df = df[~df.title.str.contains(r'[^\\x00-\\x7F]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#resets the index\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see how many times each book comes up rated (calls the collection package)\n",
    "from collections import Counter\n",
    "Counter(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see how many times multiple reviewers rated the same title\n",
    "df.groupby(\"reviewerName\")[\"title\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all the different users rated this one title that have multiple users\n",
    "same_names = df[df['title'] == 'Anne of Avonlea'][\"reviewerName\"].unique()\n",
    "for name in same_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# filters the unique reviewerName for their corresponding title and reviewRatings\n",
    "df1 = df.set_index(['reviewerName', 'title']).sort_index()\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts dataframe to dictionary\n",
    "d = (df.groupby('reviewerName')['title','reviewerRatings']\n",
    "     .apply(lambda x: dict(x.values))\n",
    "     .to_dict())\n",
    "# use groupy with lambda function per reviewerName,\n",
    "# then use to_dict to convert from DataFrame to dictionary\n",
    "d\n",
    "\n",
    "# another way to perform the above\n",
    "# d = df.groupby('reviewerName').apply(lambda x: x.set_index('title')['reviewerRatings'].to_dict()).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[solve IOPub data rate exceeded](https://stackoverflow.com/questions/43288550/iopub-data-rate-exceeded-in-jupyter-notebook-when-viewing-image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# returns a distance-based similarity score for person1 and person2\n",
    "def sim_distance(prefs,person1,person2):\n",
    "    # get the list of shared_items\n",
    "    si = {} \n",
    "    for item in prefs[person1]:\n",
    "        if item in prefs[person2]:\n",
    "            si[item]=1\n",
    "    \n",
    "    # if they have no ratings in common, return 0\n",
    "    if len(si) == 0: \n",
    "        return 0\n",
    "    \n",
    "    # add up the squares of all the differences\n",
    "    sum_of_squares = sum([pow(prefs[person1][item] - prefs[person2][item],2) \n",
    "                          for item in prefs[person1] if item in prefs[person2]])\n",
    "    \n",
    "    return 1/(1+sum_of_squares)\n",
    "\n",
    "sim_distance(d, 'Charles G', 'Maureen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# returns the Pearson correlation coefficient for person1 and person2\n",
    "def sim_pearson(prefs,person1,person2):\n",
    "    # get the list of shared_items\n",
    "    si = {}\n",
    "    for item in prefs[person1]:\n",
    "        if item in prefs[person2]:\n",
    "            si[item]=1\n",
    "    \n",
    "    # find the number of elements\n",
    "    n = len(si)\n",
    "    \n",
    "    # if they have no ratings in common, return 0\n",
    "    if len(si) == 0: \n",
    "        return 0\n",
    "    \n",
    "    # add up all the preferences\n",
    "    sum1 = sum([prefs[person1][it] for it in si]) # it is all items in si\n",
    "    sum2 = sum([prefs[person2][it] for it in si])\n",
    "    \n",
    "    # sum up the squares\n",
    "    sum1Sq = sum([pow(prefs[person1][it], 2) for it in si])\n",
    "    sum2Sq = sum([pow(prefs[person2][it], 2) for it in si])\n",
    "    \n",
    "    # sum up the products\n",
    "    pSum = sum([prefs[person1][it] * prefs[person2][it] for it in si])\n",
    "    \n",
    "    # calculate Pearson score\n",
    "    num = pSum - (sum1 * sum2 / n)\n",
    "    den = sqrt((sum1Sq - pow(sum1, 2)/n) * (sum2Sq - pow(sum2, 2)/n))\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    \n",
    "    r = num/den\n",
    "    \n",
    "    return r\n",
    "\n",
    "sim_pearson(d, 'Charles G', 'Maureen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for similarity to myself (Maureen) using Euclidean distance score\n",
    "# n is the length of shared items si\n",
    "\n",
    "def top_matches(prefs, person, n=10, similarity = sim_distance):\n",
    "    # sets other parameter to exclude myself\n",
    "    scores = [(similarity(prefs,person,other), other)\n",
    "            for other in prefs if other!=person]\n",
    "    \n",
    "    # sort the list so the higest score appear at the top\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:n] # slices from first index to last index\n",
    "\n",
    "top_matches(d, 'Maureen', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for similarity to myself (Maureen) using Pearson correlation score\n",
    "top_matches(d, 'Maureen', n=10, similarity = sim_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets recommendation for a person by using a weighted average of all other users\n",
    "# Using Euclidean distance score\n",
    "def get_recommendations(prefs, person, similarity = sim_distance):\n",
    "    totals = {} \n",
    "    # get the list of each book for sum of similarity score x actual rating\n",
    "    simSums = {} # get the list of each book for sum of similartiy score\n",
    "    for other in prefs:\n",
    "        # don't compare me to myself\n",
    "        if other == person:\n",
    "            continue\n",
    "        sim = similarity(prefs, person, other) # then use sim\n",
    "        \n",
    "        # ignore scores of zero or lower\n",
    "        if sim <= 0:\n",
    "            continue\n",
    "        for item in prefs[other]: # item in prefs from sim_distance\n",
    "            \n",
    "            # only score books I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # similarity * score\n",
    "                totals.setdefault(item,0) \n",
    "                totals[item] += prefs[other][item] * sim\n",
    "                # sum of similarities\n",
    "                simSums.setdefault(item,0)\n",
    "                simSums[item] += sim\n",
    "            # setdefault calls the key, and returns 0 if it does not exist\n",
    "            # similar to get()\n",
    "            \n",
    "    # create the normalized list\n",
    "    rankings = [(total/simSums[item], item) for item, total in totals.items()]\n",
    "    # total(singular item, sum of (sim*actual ratings for each user)),\n",
    "    # divide by simSum for each item,\n",
    "    # and run total and item for each item, \n",
    "    # while adding each result in the totals list,\n",
    "    # then returns a dictionary by calling totals.items()\n",
    "    # items() returns a list of dictionary\n",
    "    \n",
    "    # return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings\n",
    "\n",
    "get_recommendations(d, 'Maureen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets recommendation for a person by using a weighted average of all other users\n",
    "# Using Pearson correlation score\n",
    "get_recommendations(d, 'Maureen', similarity = sim_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inverts the data set for item-centric matrix\n",
    "\n",
    "def transform_prefs(prefs):\n",
    "    result={} # get the list of the transformed results\n",
    "    for person in prefs: # prefs -> person (user from the preference dataset)\n",
    "        for item in prefs[person]: # prefs[person] -> item (rating from user)\n",
    "            result.setdefault(item,{}) \n",
    "            # add ratings to the transformed results list\n",
    "            # by calling the ratings (keys) from the users (prefs[person])\n",
    "            # setdefault calls the key, \n",
    "            # and returns empty list {} if it does not exist\n",
    "            # similar to get()\n",
    "            \n",
    "            # flip item and person (flips user with ratings)\n",
    "            result[item][person] = prefs[person][item]\n",
    "    return result\n",
    "\n",
    "transform_prefs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find similar books for each of the book using ranking function above,\n",
    "# top_matches(sim_distance)\n",
    "\n",
    "def calculate_similar_items(prefs, n=10):\n",
    "    # create a dictionary of items showing which other items\n",
    "    # they are most similar to\n",
    "    result = {} \n",
    "    \n",
    "    # invert the preference matrix to be item-centric\n",
    "    itemPrefs = transform_prefs(prefs)\n",
    "    c = 0 # assigns a new count of dataset\n",
    "    for item in itemPrefs:\n",
    "        \n",
    "        # status update for large dataset\n",
    "        c += 1 # implement loop to add to dataset\n",
    "        if c%100 == 0: \n",
    "        # if module is 0, then print length of dataset and length of dictionary\n",
    "            print(\"%d / %d\" % (c, len(itemPrefs)))\n",
    "        \n",
    "        # find the most similar items to this one (calls the ranking function)\n",
    "        scores = top_matches(itemPrefs, item, n=n, similarity = sim_distance)\n",
    "        # item is now used instead of person since we inverted the matrix\n",
    "        result[item] = scores\n",
    "        # adds similar items (scores) to the result[item] list\n",
    "    return result\n",
    "\n",
    "itemsim = calculate_similar_items(d)\n",
    "itemsim\n",
    "\n",
    "#substitute sim_pearson for Pearson correlation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend book using similar function above, \n",
    "# itemsim(calculate_similar_items(d))\n",
    "\n",
    "def get_recommendedItems(prefs, itemMatch, user):\n",
    "    userRatings = prefs[user] # creates a list for the self user\n",
    "    scores = {}\n",
    "    # get the list of similarity score for similar books, \n",
    "    # from the sum of similarity score (book read) x actual rating (book read)\n",
    "    # against similar books\n",
    "    totalSim= {} # get the list of total similarity score for similar books,\n",
    "    # from the sum of similartiy score (books) against similar books\n",
    "    \n",
    "    # Loop over items (books) rated by this user \n",
    "    for (item, rating) in userRatings.items():\n",
    "    # items that are already self rated, add to the list for self user \n",
    "        \n",
    "        # Loop over items similar to this one\n",
    "        for (similarity, item2) in itemMatch[item]:\n",
    "        # item2 are items that are not self rated, \n",
    "        # we calculate the similarity distance between\n",
    "        # other items that are rated by other users\n",
    "        # itemMatch from calculate_similar_items function\n",
    "            \n",
    "            # Ignore if this user has already rated this item\n",
    "            if item2 in userRatings:\n",
    "                continue\n",
    "            # if the other items (item2) are already self rated, then we ignore\n",
    "                \n",
    "            # Weighted sum of rating times similarity for other items\n",
    "            scores.setdefault(item2,0)\n",
    "            scores[item2] += similarity * rating\n",
    "            # setdefault calls the key, and returns 0 if it does not exist\n",
    "            # similar to get()\n",
    "            \n",
    "            # Sum of all the similarities for other items\n",
    "            totalSim.setdefault(item2,0)\n",
    "            totalSim[item2] += similarity\n",
    "            # setdefault calls the key, and returns 0 if it does not exist\n",
    "            # similar to get()\n",
    "            \n",
    "    # Divide each total score by total weighting to get an average\n",
    "    rankings=[(score/totalSim[item],item) for item, score in scores.items()]\n",
    "    # score(singular item, sum of (sim*actual ratings for each movie)),\n",
    "    # divide by totalSim for each item,\n",
    "    # and run score and item for each item, \n",
    "    # while adding each result in the scores list,\n",
    "    # then returns a dictionary by calling scores.items()\n",
    "    # items() returns a list of dictionary\n",
    "    \n",
    "    # Return the rankings from highest to lowest\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings\n",
    "\n",
    "get_recommendedItems(d, itemsim, 'Maureen')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "46px",
    "left": "802px",
    "top": "32px",
    "width": "158px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
